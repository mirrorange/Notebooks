{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Anime StyleGAN2","private_outputs":true,"provenance":[{"file_id":"1Pv8OIFlonha4KeYyY2oEFaK4mG-alaWF","timestamp":1614296184169},{"file_id":"1QKhT_I-BQ0uuxGK-c7eAUi6lvmXzNoAE","timestamp":1577998422422},{"file_id":"1ShgW6wohEFQtqs_znMna3dzrcVoABKIH","timestamp":1576781166392}],"collapsed_sections":["lgdNVt8Vzh6h","Ja-iZ5xJtWWe"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"U4lpsM8Jl6Uc"},"source":["# Anime StyleGAN2\n"]},{"cell_type":"markdown","metadata":{"id":"PU9EFsP6mNJy"},"source":["## 准备工作"]},{"cell_type":"code","metadata":{"id":"PzDuIoMcqfBT"},"source":["%tensorflow_version 1.x\n","import tensorflow as tf\n","!pip install googledrivedownloader\n","\n","\n","# Download the code\n","%cd /content/\n","!git clone https://github.com/NVlabs/stylegan2.git\n","%cd /content/stylegan2\n","\n","!nvcc test_nvcc.cu -o test_nvcc -run\n","\n","print('Tensorflow version: {}'.format(tf.__version__) )\n","!nvidia-smi -L\n","print('GPU Identified at: {}'.format(tf.test.gpu_device_name()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cwVXBFaSuoIU"},"source":["# Download the model of choice\n","import argparse\n","import numpy as np\n","import PIL.Image\n","import dnnlib\n","import dnnlib.tflib as tflib\n","import re\n","import sys\n","from io import BytesIO\n","import IPython.display\n","import numpy as np\n","from math import ceil\n","from PIL import Image, ImageDraw\n","import imageio\n","\n","import pretrained_networks\n","\n","import hashlib \n","\n","from google_drive_downloader import GoogleDriveDownloader as gdd\n","\n","# StyleGAN2 Danbooru Portrait\n","url = 'https://drive.google.com/open?id=1Q4AJVkCP5Ra2mZL_GVhromRjKzu0T398'\n","#'https://drive.google.com/open?id=1BHeqOZ58WZ-vACR2MJkh1ZVbJK2B-Kle'\n","model_id = url.replace('https://drive.google.com/open?id=', '')\n","\n","network_pkl = '/content/models/model_%s.pkl' % model_id#(hashlib.md5(model_id.encode()).hexdigest())\n","gdd.download_file_from_google_drive(file_id=model_id,\n","                                    dest_path=network_pkl)\n","\n","\n","\n","\n","# If downloads fails, due to 'Google Drive download quota exceeded' you can try downloading manually from your own Google Drive account\n","# network_pkl = \"/content/drive/My Drive/GAN/stylegan2-ffhq-config-f.pkl\"\n","\n","print('Loading networks from \"%s\"...' % network_pkl)\n","_G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n","noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t0H9EaMQkWb5"},"source":["from IPython import display as ipythondisplay\n","import io\n","import os\n","import base64\n","from IPython.display import HTML\n","\n","def show_video(vid):\n","  #mp4list = [video\n","  #if len(mp4list) > 0:\n","  ext = os.path.splitext(vid)[-1][1:]\n","  video = io.open(vid, 'r+b').read()\n","  #encoded = base64.b64encode(video)\n","  ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n","              loop controls style=\"height: 400px;\">\n","              <source src=\"data:video/{1}';base64,{0}\" type=\"video/{1}\" />\n","              </video>'''.format(base64.b64encode(video).decode('ascii'), ext)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zxbhe4uLvF_a"},"source":["# Useful utility functions...\n","\n","# Generates a list of images, based on a list of latent vectors (Z), and a list (or a single constant) of truncation_psi's.\n","def generate_images_in_w_space(dlatents, truncation_psi):\n","    Gs_kwargs = dnnlib.EasyDict()\n","    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n","    Gs_kwargs.randomize_noise = False\n","    Gs_kwargs.truncation_psi = truncation_psi\n","    dlatent_avg = Gs.get_var('dlatent_avg') # [component]\n","\n","    imgs = []\n","    for row, dlatent in log_progress(enumerate(dlatents), name = \"Generating images\"):\n","        #row_dlatents = (dlatent[np.newaxis] - dlatent_avg) * np.reshape(truncation_psi, [-1, 1, 1]) + dlatent_avg\n","        dl = (dlatent-dlatent_avg)*truncation_psi   + dlatent_avg\n","        row_images = Gs.components.synthesis.run(dlatent,  **Gs_kwargs)\n","        imgs.append(PIL.Image.fromarray(row_images[0], 'RGB'))\n","    return imgs       \n","\n","def generate_images(zs, truncation_psi):\n","    Gs_kwargs = dnnlib.EasyDict()\n","    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n","    Gs_kwargs.randomize_noise = False\n","    if not isinstance(truncation_psi, list):\n","        truncation_psi = [truncation_psi] * len(zs)\n","        \n","    imgs = []\n","    for z_idx, z in log_progress(enumerate(zs), size = len(zs), name = \"Generating images\"):\n","        Gs_kwargs.truncation_psi = truncation_psi[z_idx]\n","        noise_rnd = np.random.RandomState(1) # fix noise\n","        tflib.set_vars({var: noise_rnd.randn(*var.shape.as_list()) for var in noise_vars}) # [height, width]\n","        images = Gs.run(z, None, **Gs_kwargs) # [minibatch, height, width, channel]\n","        imgs.append(PIL.Image.fromarray(images[0], 'RGB'))\n","    return imgs\n","\n","def generate_zs_from_seeds(seeds):\n","    zs = []\n","    for seed_idx, seed in enumerate(seeds):\n","        rnd = np.random.RandomState(seed)\n","        z = rnd.randn(1, *Gs.input_shape[1:]) # [minibatch, component]\n","        zs.append(z)\n","    return zs\n","\n","# Generates a list of images, based on a list of seed for latent vectors (Z), and a list (or a single constant) of truncation_psi's.\n","def generate_images_from_seeds(seeds, truncation_psi):\n","    return generate_images(generate_zs_from_seeds(seeds), truncation_psi)\n","\n","def saveImgs(imgs, location):\n","  for idx, img in log_progress(enumerate(imgs), size = len(imgs), name=\"Saving images\"):\n","    file = location+ str(idx) + \".png\"\n","    img.save(file)\n","\n","def imshow(a, format='png', jpeg_fallback=True):\n","  a = np.asarray(a, dtype=np.uint8)\n","  str_file = BytesIO()\n","  PIL.Image.fromarray(a).save(str_file, format)\n","  im_data = str_file.getvalue()\n","  try:\n","    disp = IPython.display.display(IPython.display.Image(im_data))\n","  except IOError:\n","    if jpeg_fallback and format != 'jpeg':\n","      print ('Warning: image was too large to display in format \"{}\"; '\n","             'trying jpeg instead.').format(format)\n","      return imshow(a, format='jpeg')\n","    else:\n","      raise\n","  return disp\n","\n","def showarray(a, fmt='png'):\n","    a = np.uint8(a)\n","    f = StringIO()\n","    PIL.Image.fromarray(a).save(f, fmt)\n","    IPython.display.display(IPython.display.Image(data=f.getvalue()))\n","\n","        \n","def clamp(x, minimum, maximum):\n","    return max(minimum, min(x, maximum))\n","    \n","def drawLatent(image,latents,x,y,x2,y2, color=(255,0,0,100)):\n","  buffer = PIL.Image.new('RGBA', image.size, (0,0,0,0))\n","   \n","  draw = ImageDraw.Draw(buffer)\n","  cy = (y+y2)/2\n","  draw.rectangle([x,y,x2,y2],fill=(255,255,255,180), outline=(0,0,0,180))\n","  for i in range(len(latents)):\n","    mx = x + (x2-x)*(float(i)/len(latents))\n","    h = (y2-y)*latents[i]*0.1\n","    h = clamp(h,cy-y2,y2-cy)\n","    draw.line((mx,cy,mx,cy+h),fill=color)\n","  return PIL.Image.alpha_composite(image,buffer)\n","             \n","  \n","def createImageGrid(images, scale=0.25, rows=1):\n","   w,h = images[0].size\n","   w = int(w*scale)\n","   h = int(h*scale)\n","   height = rows*h\n","   cols = ceil(len(images) / rows)\n","   width = cols*w\n","   canvas = PIL.Image.new('RGBA', (width,height), 'white')\n","   for i,img in enumerate(images):\n","     img = img.resize((w,h), PIL.Image.ANTIALIAS)\n","     canvas.paste(img, (w*(i % cols), h*(i // cols))) \n","   return canvas\n","\n","def convertZtoW(latent, truncation_psi=0.7, truncation_cutoff=9):\n","  dlatent = Gs.components.mapping.run(latent, None) # [seed, layer, component]\n","  dlatent_avg = Gs.get_var('dlatent_avg') # [component]\n","  for i in range(truncation_cutoff):\n","    dlatent[0][i] = (dlatent[0][i]-dlatent_avg)*truncation_psi + dlatent_avg\n","    \n","  return dlatent\n","\n","def interpolate(zs, steps):\n","   out = []\n","   for i in range(len(zs)-1):\n","    for index in range(steps):\n","     fraction = index/float(steps) \n","     out.append(zs[i+1]*fraction + zs[i]*(1-fraction))\n","   return out\n","\n","# Taken from https://github.com/alexanderkuk/log-progress\n","def log_progress(sequence, every=1, size=None, name='Items'):\n","    from ipywidgets import IntProgress, HTML, VBox\n","    from IPython.display import display\n","\n","    is_iterator = False\n","    if size is None:\n","        try:\n","            size = len(sequence)\n","        except TypeError:\n","            is_iterator = True\n","    if size is not None:\n","        if every is None:\n","            if size <= 200:\n","                every = 1\n","            else:\n","                every = int(size / 200)     # every 0.5%\n","    else:\n","        assert every is not None, 'sequence is iterator, set every'\n","\n","    if is_iterator:\n","        progress = IntProgress(min=0, max=1, value=1)\n","        progress.bar_style = 'info'\n","    else:\n","        progress = IntProgress(min=0, max=size, value=0)\n","    label = HTML()\n","    box = VBox(children=[label, progress])\n","    display(box)\n","\n","    index = 0\n","    try:\n","        for index, record in enumerate(sequence, 1):\n","            if index == 1 or index % every == 0:\n","                if is_iterator:\n","                    label.value = '{name}: {index} / ?'.format(\n","                        name=name,\n","                        index=index\n","                    )\n","                else:\n","                    progress.value = index\n","                    label.value = u'{name}: {index} / {size}'.format(\n","                        name=name,\n","                        index=index,\n","                        size=size\n","                    )\n","            yield record\n","    except:\n","        progress.bar_style = 'danger'\n","        raise\n","    else:\n","        progress.bar_style = 'success'\n","        progress.value = index\n","        label.value = \"{name}: {index}\".format(\n","            name=name,\n","            index=str(index or '?')\n","        )\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U-uy6ioomiRO"},"source":["## 生成单张随机图像"]},{"cell_type":"code","metadata":{"id":"x1OQLtApm5lO"},"source":["# 创建文件夹\n","!rm -rf /content/imgs/\n","!mkdir /content/imgs/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BQIhdSRcXC-Q"},"source":["# 生成随机种子\n","seeds = np.random.randint(10000000, size=25)\n","print(seeds)\n","\n","# 生成并保存图像\n","imgs = generate_images_from_seeds(seeds, 0.5)\n","saveImgs(imgs,\"/content/imgs/\")\n","imshow(createImageGrid(imgs, 1 , 5))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WCsc3OgXzNQB"},"source":["# 下载图像\n","!tar -czvf /content/images.tar.gz /content/imgs/\n","from google.colab import files\n","files.download('/content/images.tar.gz')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lCcewD8V8Yqo"},"source":["# 清理文件\n","!rm /content/imgs/*"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Unq-BHQnr3n"},"source":["## 生成插值动画帧"]},{"cell_type":"code","metadata":{"id":"_aZvophLZQOw"},"source":["# 生成插值动画帧\n","# 请在右侧表单修改随机种子\n","\n","seed1 = 40152 #@param {type:\"number\"}\n","seed2 = 61480 #@param {type:\"number\"}\n","\n","zs = generate_zs_from_seeds([seed1, seed2])\n","\n","latent1 = zs[0]\n","latent2 = zs[1]\n","\n","number_of_steps = 25\n","\n","imgs = generate_images(interpolate([latent1,latent2],number_of_steps), 1.0)\n","number_of_images = len(imgs)\n","saveImgs(imgs,\"/content/imgs/\")\n","imshow(createImageGrid(imgs, 0.7 , 5))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"di2h1Ckz1o3P"},"source":["# 下载图像\n","!tar -czvf /content/images.tar.gz /content/imgs/\n","from google.colab import files\n","files.download('/content/images.tar.gz')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-yT0hGor1soG"},"source":["# 清理文件\n","!rm /content/imgs/*"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yuR9GvsNn4A8"},"source":["## 生成MP4格式插值动画"]},{"cell_type":"code","metadata":{"id":"TwXUbkVJXckp"},"source":["# 生成一个MP4动画\n","\n","# 在右侧填写随机种子，以逗号分隔\n","seeds = \"421645,6149575,3487643,3766864,3857159,5360657,3720613\" #@param {type:\"string\"}\n","\n","zs = generate_zs_from_seeds(eval(\"[\" + seeds + \"]\"))\n","\n","number_of_steps = 10\n","imgs = generate_images(interpolate(zs,number_of_steps), 0.7)\n","\n","# 将生成的图像转换为MP4\n","%mkdir out\n","movieName = 'out/mov.mp4'\n","\n","with imageio.get_writer(movieName, mode='I') as writer:\n","    for image in log_progress(list(imgs), name = \"Creating animation\"):\n","        writer.append_data(np.array(image))\n","show_video(movieName)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U6T7h0gpsIJK"},"source":["import scipy\n","\n","grid_size = [3,3]\n","image_shrink = 1\n","image_zoom = 1\n","duration_sec = 10\n","smoothing_sec = 1.0\n","mp4_fps = 20\n","mp4_codec = 'libx264'\n","mp4_bitrate = '2M'#8M\n","random_seed = np.random.randint(0, 999)#405\n","mp4_file = 'random_grid_%s.mp4' % random_seed\n","minibatch_size = 8\n","truncation_psi= 0.7\n","\n","num_frames = int(np.rint(duration_sec * mp4_fps))\n","random_state = np.random.RandomState(random_seed)\n","\n","# 生成 latent vectors\n","shape = [num_frames, np.prod(grid_size)] + Gs.input_shape[1:] # [frame, image, channel, component]\n","all_latents = random_state.randn(*shape).astype(np.float32)\n","all_latents = scipy.ndimage.gaussian_filter(all_latents, [smoothing_sec * mp4_fps] + [0] * len(Gs.input_shape), mode='wrap')\n","all_latents /= np.sqrt(np.mean(np.square(all_latents)))\n","\n","\n","def create_image_grid(images, grid_size=None):\n","    assert images.ndim == 3 or images.ndim == 4\n","    num, img_h, img_w, channels = images.shape\n","\n","    if grid_size is not None:\n","        grid_w, grid_h = tuple(grid_size)\n","    else:\n","        grid_w = max(int(np.ceil(np.sqrt(num))), 1)\n","        grid_h = max((num - 1) // grid_w + 1, 1)\n","\n","    grid = np.zeros([grid_h * img_h, grid_w * img_w, channels], dtype=images.dtype)\n","    for idx in range(num):\n","        x = (idx % grid_w) * img_w\n","        y = (idx // grid_w) * img_h\n","        grid[y : y + img_h, x : x + img_w] = images[idx]\n","    return grid\n","\n","#def next_power_of_2(x):  \n","#  return 1 if x == 0 else 2**(x - 1).bit_length()\n","\n","# Frame generation func for moviepy.\n","def make_frame(t):\n","    frame_idx = int(np.clip(np.round(t * mp4_fps), 0, num_frames - 1))\n","    latents = all_latents[frame_idx]\n","    fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n","    images = Gs.run(latents, None, truncation_psi=truncation_psi,\n","                          randomize_noise=False, output_transform=fmt, \n","                          minibatch_size=16)\n","\n","    grid = create_image_grid(images, grid_size)\n","    if image_zoom > 1:\n","        grid = scipy.ndimage.zoom(grid, [image_zoom, image_zoom, 1], order=0)\n","    if grid.shape[2] == 1:\n","        grid = grid.repeat(3, 2) # grayscale => RGB\n","    return grid\n","\n","# 生成视频\n","import moviepy.editor\n","video_clip = moviepy.editor.VideoClip(make_frame, duration=duration_sec)\n","video_clip.write_videofile(mp4_file, fps=mp4_fps, codec=mp4_codec, bitrate=mp4_bitrate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Po7eQSxav8qj"},"source":["\n","# 展示视频\n","show_video(mp4_file)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lgdNVt8Vzh6h"},"source":["### Corase "]},{"cell_type":"code","metadata":{"id":"tipAb-M0zkw4"},"source":["import scipy\n","\n","duration_sec = 10.0\n","smoothing_sec = 1.0\n","mp4_fps = 20\n","truncation_psi = 0.7\n","\n","num_frames = int(np.rint(duration_sec * mp4_fps))\n","#random_seed = 500\n","random_state = np.random.RandomState(int(random_seed))\n","\n","\n","h, w = Gs.output_shape[-2:]\n","#src_seeds = [601]\n","dst_seeds = [501, 702]\n","#style_ranges = ([0] * 7 + [range(8,16)]) * len(dst_seeds)\n","num_styles = Gs.components.mapping.output_shape[1]\n","#style_ranges = ([0] * (num_styles // 2) + [range(num_styles // 2, num_styles)]) * len(dst_seeds)\n","style_ranges = (list(range(0, num_styles//2))) * len(dst_seeds)\n","\n","\n","fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n","synthesis_kwargs = dict(output_transform=fmt, truncation_psi=truncation_psi, minibatch_size=16)\n","\n","shape = [num_frames] + Gs.input_shape[1:] # [frame, image, channel, component]\n","src_latents = random_state.randn(*shape).astype(np.float32)\n","src_latents = scipy.ndimage.gaussian_filter(src_latents,\n","                                            smoothing_sec * mp4_fps,\n","                                            mode='wrap')\n","src_latents /= np.sqrt(np.mean(np.square(src_latents)))\n","\n","dst_latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in dst_seeds)\n","\n","\n","src_dlatents = Gs.components.mapping.run(src_latents, None) # [seed, layer, component]\n","dst_dlatents = Gs.components.mapping.run(dst_latents, None) # [seed, layer, component]\n","src_images = Gs.components.synthesis.run(src_dlatents, randomize_noise=False, **synthesis_kwargs)\n","dst_images = Gs.components.synthesis.run(dst_dlatents, randomize_noise=False, **synthesis_kwargs)\n","\n","\n","canvas = PIL.Image.new('RGB', (w * (len(dst_seeds) + 1), h * 2), 'white')\n","    \n","for col, dst_image in enumerate(list(dst_images)):\n","    canvas.paste(PIL.Image.fromarray(dst_image, 'RGB'), ((col + 1) * h, 0))\n","\n","def make_frame(t):\n","    frame_idx = int(np.clip(np.round(t * mp4_fps), 0, num_frames - 1))\n","    src_image = src_images[frame_idx]\n","    canvas.paste(PIL.Image.fromarray(src_image, 'RGB'), (0, h))\n","    \n","    for col, dst_image in enumerate(list(dst_images)):\n","        col_dlatents = np.stack([dst_dlatents[col]])\n","        col_dlatents[:, style_ranges[col]] = src_dlatents[frame_idx, style_ranges[col]]\n","        col_images = Gs.components.synthesis.run(col_dlatents, randomize_noise=False, **synthesis_kwargs)\n","        for row, image in enumerate(list(col_images)):\n","            canvas.paste(PIL.Image.fromarray(image, 'RGB'), ((col + 1) * h, (row + 1) * w))\n","    return np.array(canvas)\n","    \n","# Generate video.\n","import moviepy.editor\n","mp4_file = 'output.mp4'\n","mp4_codec = 'libx264'\n","mp4_bitrate = '2M'#8M\n","\n","video_clip = moviepy.editor.VideoClip(make_frame, duration=duration_sec)\n","video_clip.write_videofile(mp4_file, fps=mp4_fps, codec=mp4_codec, bitrate=mp4_bitrate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0MWhyNPXzodW"},"source":["show_video(mp4_file)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ja-iZ5xJtWWe"},"source":["### Fine"]},{"cell_type":"code","metadata":{"id":"D2_HVLodscDg"},"source":["import scipy\n","\n","duration_sec = 20.0\n","smoothing_sec = 1.0\n","mp4_fps = 20\n","\n","num_frames = int(np.rint(duration_sec * mp4_fps))\n","random_seed = 200\n","random_state = np.random.RandomState(random_seed)\n","\n","\n","w = 512\n","h = 512\n","style_num = Gs.components.mapping.output_shape[1]\n","style_ranges = [range(style_num//2, style_num)]\n","\n","fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n","synthesis_kwargs = dict(output_transform=fmt, truncation_psi=0.25, minibatch_size=8)\n","\n","shape = [num_frames] + Gs.input_shape[1:] # [frame, image, channel, component]\n","src_latents = random_state.randn(*shape).astype(np.float32)\n","src_latents = scipy.ndimage.gaussian_filter(src_latents,\n","                                            smoothing_sec * mp4_fps,\n","                                            mode='wrap')\n","src_latents /= np.sqrt(np.mean(np.square(src_latents)))\n","\n","dst_latents = np.stack([random_state.randn(Gs.input_shape[1])])\n","\n","\n","src_dlatents = Gs.components.mapping.run(src_latents, None) # [seed, layer, component]\n","dst_dlatents = Gs.components.mapping.run(dst_latents, None) # [seed, layer, component]\n","\n","\n","def make_frame(t):\n","    frame_idx = int(np.clip(np.round(t * mp4_fps), 0, num_frames - 1))\n","    col_dlatents = np.stack([dst_dlatents[0]])\n","    col_dlatents[:, style_ranges[0]] = src_dlatents[frame_idx, style_ranges[0]]\n","    col_images = Gs.components.synthesis.run(col_dlatents, randomize_noise=False, **synthesis_kwargs)\n","    return col_images[0]\n","    \n","# Generate video.\n","import moviepy.editor\n","mp4_file = 'fine_%s.mp4' % (random_seed)\n","mp4_codec = 'libx264'\n","mp4_bitrate = '2M'\n","\n","video_clip = moviepy.editor.VideoClip(make_frame, duration=duration_sec)\n","video_clip.write_videofile(mp4_file, fps=mp4_fps, codec=mp4_codec, bitrate=mp4_bitrate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ayK-CUC-sfYv"},"source":["show_video(mp4_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F252sUipCOgO"},"source":["# If you want to store files to your Google drive, run this cell...\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","import os\n","import time\n","print( os.getcwd() )\n","location = \"/content/gdrive/My Drive/PythonTests\"\n","print( os.listdir(location) )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GofpNwi5aLl9"},"source":["# more complex example, interpolating in W instead of Z space.\n","zs = generate_zs_from_seeds([421645,6149575,3487643,3766864 ,3857159,5360657,3720613 ])\n","\n","# It seems my truncation_psi is slightly less efficient in W space - I probably introduced an error somewhere...\n","\n","dls = []\n","for z in zs:\n","  dls.append(convertZtoW(z ,truncation_psi=1.0))\n","\n","number_of_steps = 100\n","\n","imgs = generate_images_in_w_space(interpolate(dls,number_of_steps), 1.0)\n","\n","%mkdir out\n","movieName = 'out/mov.mp4'\n","\n","with imageio.get_writer(movieName, mode='I') as writer:\n","    for image in log_progress(list(imgs), name = \"Creating animation\"):\n","        writer.append_data(np.array(image))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MXRNSH97kZpj"},"source":["show_video(movieName)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7pH9q_7MzP2T"},"source":["#from IPython.display import Image, display\n","\n","def draw_truncation_trick_figure(png, Gs, w=512, h=512, seeds=[91, 81, 388], psis=[1, 0.7, 0.5, 0, -0.5, -1]):\n","    #print(png)\n","    latents = np.stack(np.random.RandomState(seed).randn(Gs.input_shape[1]) for seed in seeds)\n","    dlatents = Gs.components.mapping.run(latents, None) # [seed, layer, component]\n","    dlatent_avg = Gs.get_var('dlatent_avg') # [component]\n","\n","    canvas = PIL.Image.new('RGB', (w * len(psis), h * len(seeds)), 'white')\n","    for row, dlatent in enumerate(list(dlatents)):\n","        row_dlatents = (dlatent[np.newaxis] - dlatent_avg) * np.reshape(psis, [-1, 1, 1]) + dlatent_avg\n","        row_images = Gs.components.synthesis.run(row_dlatents, randomize_noise=False, **synthesis_kwargs)\n","        for col, image in enumerate(list(row_images)):\n","            canvas.paste(PIL.Image.fromarray(image, 'RGB'), (col * w, row * h))\n","            \n","    canvas.save(png)\n","    IPython.display.display(IPython.display.Image(png, width=1024))\n","        #PIL.Image(png, width=1024))\n","h, w = Gs.output_shape[-2:]\n","draw_truncation_trick_figure('output.png', Gs, w=w, h=h, seeds=[901, 888], psis=[1, 0.7, 0.5, 0, -0.5, -1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rYdsgv4i6YPl"},"source":["## 从已知图像找到最接近的可生成图像"]},{"cell_type":"code","metadata":{"id":"urzy8lw76j_r"},"source":["!mkdir projection\n","!mkdir projection/imgs\n","!mkdir projection/out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C-MHoRBBrjgV"},"source":["# 现在将单个图像上传到 'stylegan2/projection/imgs'。 图片应为彩色PNG，尺寸为1024x1024。\n","%cd /content/stylegan2/projection/imgs\n","from google.colab import files\n","uploaded = files.upload()\n","for fn in uploaded.keys():\n","  print('用户上传了大小为 {length} bytes 的文件\"{name}\"'.format(\n","      name=fn, length=len(uploaded[fn])))\n","%cd /content/stylegan2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IDLJBbpz6n4k"},"source":["# 将上传的图像转换为TFRecords\n","import dataset_tool\n","dataset_tool.create_from_images(\"./projection/records/\", \"./projection/imgs/\", True)\n","!rm 'projection/records/-r10.tfrecords'\n","\n","# 运行投影\n","import run_projector\n","import projector\n","import training.dataset\n","import training.misc\n","import os \n","import cv2\n","\n","def project_real_images(dataset_name, data_dir, num_images, num_snapshots):\n","    proj = projector.Projector()\n","    proj.set_network(Gs)\n","\n","    print('Loading images from \"%s\"...' % dataset_name)\n","    dataset_obj = training.dataset.load_dataset(data_dir=data_dir, tfrecord_dir=dataset_name, max_label_size=0, verbose=True, repeat=False, shuffle_mb=0)\n","    print(dataset_obj.shape)\n","    print(Gs.output_shape)\n","    assert dataset_obj.shape == Gs.output_shape[1:]\n","\n","    for image_idx in range(num_images):\n","        print('Projecting image %d/%d ...' % (image_idx, num_images))\n","        images, _labels = dataset_obj.get_minibatch_np(1)\n","        images = training.misc.adjust_dynamic_range(images, [0, 255], [-1, 1])\n","        run_projector.project_image(proj, targets=images, png_prefix=dnnlib.make_run_dir_path('projection/out/image%04d-' % image_idx), num_snapshots=num_snapshots)\n","\n","project_real_images(\"records\",\"./projection\",1,100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OmjPpjFU6yq3"},"source":["# 生成视频\n","\n","import glob\n","\n","imgs = sorted(glob.glob(\"projection/out/*step*.png\"))\n","\n","target_imgs = sorted(glob.glob(\"projection/out/*target*.png\"))\n","assert len(target_imgs) == 1, \"More than one target found?\"\n","target_img = imageio.imread(target_imgs[0])\n","\n","movieName = \"projection/movie.mp4\"\n","with imageio.get_writer(movieName, mode='I') as writer:\n","    for filename in log_progress(imgs, name = \"Creating animation\"):\n","        image = imageio.imread(filename)\n","\n","        # Concatenate images with original target image\n","        w,h = image.shape[0:2]\n","        canvas = PIL.Image.new('RGBA', (w*2,h), 'white')\n","        canvas.paste(Image.fromarray(target_img), (0, 0))\n","        canvas.paste(Image.fromarray(image), (w, 0))\n","\n","        writer.append_data(np.array(canvas))  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XGVarLre63dL"},"source":["# 清理文件\n","!rm projection/out/*.*\n","!rm projection/records/*.*\n","!rm projection/imgs/*.*"],"execution_count":null,"outputs":[]}]}